{"cells": [{"cell_type": "code", "metadata": {}, "outputs": [], "source": ["!curl -O https://raw.githubusercontent.com/deepjavalibrary/d2l-java/master/tools/fix-colab-gpu.sh && bash fix-colab-gpu.sh"], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prepare Java Kernel for Google Colab\n", "Since Java is not natively supported by Colab, we need to run the following code to enable Java kernel on Colab.\n", "\n", "1. Run the cell bellow (click it and press Shift+Enter),\n", "2. (If training on CPU, skip this step) If you want to use the GPU with MXNet in DJL 0.10.0, we need CUDA 10.1 or CUDA 10.2.\nSince Colab supports CUDA 10.1, we will have to follow some steps to setup the environment.\nRefresh the page (press F5) and stay at Python runtime on GPU. Run the file fix-colab-gpu script.\n\nAnd then ensure that you have switched to CUDA 10.1.\n3. After that, switch runtime to Java and hardware to GPU.(Might require refreshing the page and switching runtime)\n", "\n", "Now you can write Java code."]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["!curl -O https://raw.githubusercontent.com/deepjavalibrary/d2l-java/master/tools/colab_build.sh && bash colab_build.sh"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"origin_pos": 0}, "source": ["# Feature-Rich Recommender Systems\n", "\n", "Interaction data is the most basic indication of users' preferences and interests. It plays a critical role in former introduced models. Yet, interaction data is usually extremely sparse and can be noisy at times. To address this issue, we can integrate side information such as features of items, profiles of users, and even in which context that the interaction occurred into the recommendation model. Utilizing these features are helpful in making recommendations in that these features can be an effective predictor of users interests especially when interaction data is lacking. As such, it is essential for recommendation models also have the capability to deal with those features and give the model some content/context awareness. To demonstrate this type of recommendation models, we introduce another task on click-through rate (CTR) for online advertisement recommendations :cite:`McMahan.Holt.Sculley.ea.2013` and present an anonymous advertising data. Targeted advertisement services have attracted widespread attention and are often framed as recommendation engines. Recommending advertisements that match users' personal taste and interest is important for click-through rate improvement.\n", "\n", "\n", "Digital marketers use online advertising to display advertisements to customers. Click-through rate is a metric that measures the number of clicks advertisers receive on their ads per number of impressions and it is expressed as a percentage calculated with the formula: \n", "\n", "$$ \\text{CTR} = \\frac{\\#\\text{Clicks}} {\\#\\text{Impressions}} \\times 100 \\% .$$\n", "\n", "Click-through rate is an important signal that indicates the effectiveness of prediction algorithms. Click-through rate prediction is a task of predicting the likelihood that something on a website will be clicked. Models on CTR prediction can not only be employed in targeted advertising systems but also in general item (e.g., movies, news, products) recommender systems, email campaigns, and even search engines. It is also closely related to user satisfaction, conversion rate, and can be helpful in setting campaign goals as it can help advertisers to set realistic expectations.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"origin_pos": 1, "tab": ["mxnet"]}, "outputs": [], "source": ["%load ../utils/djl-imports"]}, {"cell_type": "markdown", "metadata": {"origin_pos": 2}, "source": ["## An Online Advertising Dataset\n", "\n", "With the considerable advancements of Internet and mobile technology, online advertising has become an important income resource and generates vast majority of revenue in the Internet industry. It is important to display relevant advertisements or advertisements that pique users' interests so that casual visitors can be converted into paying customers. The dataset we introduced is an online advertising dataset. It consists of 34 fields, with the first column representing the target variable that indicates if an ad was clicked (1) or not (0). All the other columns are categorical features. The columns might represent the advertisement id, site or application id, device id, time, user profiles and so on. The real semantics of the features are undisclosed due to anonymization and privacy concern.\n", "\n", "The following code downloads the dataset from our server and saves it into the local data folder.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "15"}, "origin_pos": 3, "tab": ["mxnet"]}, "outputs": [], "source": ["InputStream input = new URL(\"http://d2l-data.s3-accelerate.amazonaws.com/ctr.zip\").openStream();\n", "ZipUtils.unzip(input, Paths.get(\"./\"));"]}, {"cell_type": "markdown", "metadata": {"origin_pos": 4}, "source": ["There are a training set and a test set, consisting of 15000 and 3000 samples/lines, respectively.\n", "\n", "## Dataset Wrapper\n", "\n", "For the convenience of data loading, we implement a `CTRDataset` which loads the advertising dataset from the CSV file and can be used by `DataLoader`.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import ai.djl.training.dataset.Record;\n", "\n", "public class CTRDataset extends ArrayDataset {\n", "\n", "    private boolean prepared;\n", "    private NDManager manager = Engine.getInstance().newBaseManager();\n", "    private List<Long[]> oneHotFeatures;\n", "    private List<Float> labelList;\n", "\n", "    private CTRDataset(Builder builder) {\n", "        super(builder);\n", "        this.oneHotFeatures = builder.oneHotFeatures;\n", "        this.labelList = builder.label;\n", "    }\n", "\n", "    @Override\n", "    public void prepare(Progress progress) throws IOException {\n", "        if (prepared) {\n", "            return;\n", "        }\n", "        data = new NDArray[oneHotFeatures.size()];\n", "        labels = new NDArray[labelList.size()];\n", "        for (int i = 0; i < data.length; i++) {\n", "            data[i] = manager.create(Arrays.stream(oneHotFeatures.get(i)).mapToLong(Long::longValue).toArray());\n", "            labels[i] = manager.create(labelList.get(i));\n", "        }\n", "        prepared = true;\n", "    }\n", "\n", "    /**\n", "     * {@inheritDoc}\n", "     */\n", "    @Override\n", "    public Record get(NDManager manager, long index) {\n", "        NDList datum = new NDList();\n", "        NDList label = new NDList();\n", "\n", "        datum.add(data[(int) index]);\n", "        if (labels != null) {\n", "            label.add(labels[(int) index]);\n", "        }\n", "        datum.attach(manager);\n", "        label.attach(manager);\n", "        return new Record(datum, label);\n", "    }\n", "\n", "\n", "    public static Builder builder() {\n", "        return new Builder();\n", "    }\n", "\n", "    public static final class Builder extends BaseBuilder<Builder> {\n", "\n", "        private long numFeatures;\n", "        private long featureThreshold;\n", "        private String fileName;\n", "        // feature id, category String, category code\n", "        private Map<Long, Map<String, Long>> featureMap = new ConcurrentHashMap<>();\n", "        // feature id, category String, category count\n", "        private Map<Long, Map<String, Long>> featureCount = new ConcurrentHashMap<>();\n", "        private Map<Long, Long> defaultValues = new ConcurrentHashMap<>();\n", "        private List<String[]> features = new ArrayList<>();\n", "        private List<Float> label = new ArrayList<>();\n", "        private Long[] fieldDim;\n", "        private Long[] offset;\n", "        private List<Long[]> oneHotFeatures = new ArrayList<>();\n", "        private String outputDir;\n", "\n", "        Builder() {\n", "        }\n", "\n", "        @Override\n", "        protected Builder self() {\n", "            return this;\n", "        }\n", "\n", "        public Builder setFileName(String fileName) {\n", "            this.fileName = fileName;\n", "            return this;\n", "        }\n", "\n", "        public Builder optNumFeatures(long numFeatures) {\n", "            this.numFeatures = numFeatures;\n", "            return this;\n", "        }\n", "\n", "        public Builder optFeatureThreshold(long featureThreshold) {\n", "            this.featureThreshold = featureThreshold;\n", "            return this;\n", "        }\n", "\n", "        public Builder optMapOutputDir(String outputDir) {\n", "            this.outputDir = outputDir;\n", "            return this;\n", "        }\n", "\n", "        CTRDataset build() throws IOException {\n", "\n", "            try (BufferedReader reader = Files.newBufferedReader(Paths.get(this.fileName))) {\n", "                String line;\n", "                while ((line = reader.readLine()) != null) {\n", "                    String[] record = line.trim().split(\"\\t\");\n", "                    if (record.length != this.numFeatures + 1) {\n", "                        continue;\n", "                    }\n", "                    label.add(Float.parseFloat(record[0]));\n", "                    for (int i = 1; i < numFeatures + 1; i++) {\n", "                        Map<String, Long> count = featureCount.computeIfAbsent((long) i, k -> new ConcurrentHashMap<>());\n", "                        // increment count for this category string\n", "                        count.merge(record[i], 1L, Long::sum);\n", "                    }\n", "                    features.add(Arrays.copyOfRange(record, 1, record.length));\n", "                }\n", "            }\n", "            fieldDim = new Long[(int) numFeatures];\n", "            offset = new Long[(int) numFeatures];\n", "            // reduce less frequent class\n", "            for (long i = 1L; i < numFeatures + 1; i++) {\n", "                featureCount.get(i).values().removeIf(value -> value < featureThreshold);\n", "                Map<String, Long> reducedFeatures = featureCount.get(i);\n", "                Map<String, Long> featureIndex = new ConcurrentHashMap<>();\n", "                long index = 0;\n", "                for (String feature : reducedFeatures.keySet()) {\n", "                    featureIndex.put(feature, index);\n", "                    index++;\n", "                }\n", "                featureMap.put(i, featureIndex);\n", "                defaultValues.put(i, (long) featureIndex.size());\n", "                fieldDim[(int) i - 1] = (long) featureIndex.size() - 1;\n", "            }\n", "            long sum = 0;\n", "            for (int i = 0; i < fieldDim.length; i++) {\n", "                offset[i] = sum;\n", "                sum += fieldDim[i];\n", "            }\n", "\n", "            for (String[] feature : features) {\n", "                Long[] oneHot = new Long[feature.length];\n", "                for (int i = 0; i < oneHot.length; i++) {\n", "                    oneHot[i] = featureMap.get((long) i + 1).getOrDefault(feature[i], defaultValues.get((long) i + 1)) + offset[i];\n", "                }\n", "                oneHotFeatures.add(oneHot);\n", "            }\n", "            // save feature map and default values for inference\n", "            if (outputDir != null) {\n", "                saveMap(featureMap, outputDir, \"feature_map.json\");\n", "                saveMap(defaultValues, outputDir, \"defaults.json\");\n", "            }\n", "\n", "            return new CTRDataset(this);\n", "        }\n", "\n", "        private void saveMap(Map map, String outputDir, String fileName) throws IOException {\n", "            FileWriter writer = new FileWriter(outputDir + \"/\" + fileName);\n", "            JsonUtils.GSON_PRETTY.toJson(map, writer);\n", "            writer.flush();\n", "            writer.close();\n", "        }\n", "\n", "    }\n", "}"]}, {"cell_type": "markdown", "metadata": {"origin_pos": 6}, "source": ["The following example loads the training data and print out the first record. We also need to save the feature map and default values for inference.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "16"}, "origin_pos": 7, "tab": ["mxnet"]}, "outputs": [], "source": ["CTRDataset data = CTRDataset.builder()\n", "        .optFeatureThreshold(4)\n", "        .optNumFeatures(34)\n", "        .setFileName(\"./ctr/train.csv\")\n", "        .optMapOutputDir(\"./\")\n", "        .setSampling(1, true)\n", "        .build();\n", "data.prepare();\n", "NDManager manager = NDManager.newBaseManager();\n", "Record record = data.get(manager, 0);\n", "System.out.println(record.getData().singletonOrThrow());\n", "System.out.println(record.getLabels().singletonOrThrow());"]}, {"cell_type": "markdown", "metadata": {"origin_pos": 8}, "source": ["As can be seen, all the 34 fields are categorical features. Each value represents the one-hot index of the corresponding entry. The label $0$ means that it is not clicked. This `CTRDataset` can also be used to load other datasets such as the Criteo display advertising challenge [Dataset](https://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset/) and the Avazu click-through rate prediction [Dataset](https://www.kaggle.com/c/avazu-ctr-prediction).  \n", "\n", "## Summary \n", "* Click-through rate is an important metric that is used to measure the effectiveness of advertising systems and recommender systems.\n", "* Click-through rate prediction is usually converted to a binary classification problem. The target is to predict whether an ad/item will be clicked or not based on given features.\n", "\n", "## Exercises\n", "\n", "* Can you load the Criteo and Avazu dataset with the provided `CTRDataset`. It is worth noting that the Criteo dataset consisting of real-valued features so you may have to revise the code a bit.\n"]}], "metadata": {"kernelspec": {"display_name": "Java", "language": "java", "name": "java"}, "language_info": {"codemirror_mode": "java", "file_extension": ".jshell", "mimetype": "text/x-java-source", "name": "Java", "pygments_lexer": "java", "version": "14.0.2+12"}}, "nbformat": 4, "nbformat_minor": 4}