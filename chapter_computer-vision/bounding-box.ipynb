{"cells": [{"cell_type": "code", "metadata": {}, "outputs": [], "source": ["!curl -O https://raw.githubusercontent.com/deepjavalibrary/d2l-java/master/tools/fix-colab-gpu.sh && bash fix-colab-gpu.sh"], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prepare Java Kernel for Google Colab\n", "Since Java is not natively supported by Colab, we need to run the following code to enable Java kernel on Colab.\n", "\n", "1. Run the cell bellow (click it and press Shift+Enter),\n", "2. (If training on CPU, skip this step) If you want to use the GPU with MXNet in DJL 0.10.0, we need CUDA 10.1 or CUDA 10.2.\nSince Colab supports CUDA 10.1, we will have to follow some steps to setup the environment.\nRefresh the page (press F5) and stay at Python runtime on GPU. Run the file fix-colab-gpu script.\n\nAnd then ensure that you have switched to CUDA 10.1.\n3. After that, switch runtime to Java and hardware to GPU.(Might require refreshing the page and switching runtime)\n", "\n", "Now you can write Java code."]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["!curl -O https://raw.githubusercontent.com/deepjavalibrary/d2l-java/master/tools/colab_build.sh && bash colab_build.sh"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"origin_pos": 0}, "source": ["# Object Detection and Bounding Boxes\n", ":label:`sec_bbox`\n", "\n", "\n", "In the previous section, we introduced many models for image classification. In image classification tasks, we assume that there is only one main target in the image and we only focus on how to identify the target category. However, in many situations, there are multiple targets in the image that we are interested in. We not only want to classify them, but also want to obtain their specific positions in the image. In computer vision, we refer to such tasks as object detection (or object recognition).\n", "\n", "Object detection is widely used in many fields. For example, in self-driving technology, we need to plan routes by identifying the locations of vehicles, pedestrians, roads, and obstacles in the captured video image. Robots often perform this type of task to detect targets of interest. Systems in the security field need to detect abnormal targets, such as intruders or bombs.\n", "\n", "In the next few sections, we will introduce multiple deep learning models used for object detection. Before that, we should discuss the concept of target location. First, import the packages and modules required for the experiment.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%load ../utils/djl-imports"]}, {"cell_type": "markdown", "metadata": {"origin_pos": 2}, "source": ["Next, we will load the sample images that will be used in this section. We can see there is a dog on the left side of the image and a cat on the right. They are the two main targets in this image.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"origin_pos": 3, "tab": ["mxnet"]}, "outputs": [], "source": ["// Load the original image\n", "Image imgArr = ImageFactory.getInstance()\n", "    .fromUrl(\"https://github.com/d2l-ai/d2l-en/blob/master/img/catdog.jpg?raw=true\");\n", "imgArr.getWrappedImage();"]}, {"cell_type": "markdown", "metadata": {"origin_pos": 4}, "source": ["## Bounding Box\n", "\n", "In object detection, we usually use a bounding box to describe the target location. The bounding box is a rectangular box that can be determined by the $x$ and $y$ axis coordinates in the upper-left corner and the $x$ and $y$ axis coordinates in the lower-right corner of the rectangle. We will define the bounding boxes of the dog and the cat in the image based on the coordinate information in the above image. The origin of the coordinates in the above image is the upper left corner of the image, and to the right and down are the positive directions of the $x$ axis and the $y$ axis, respectively.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "2"}, "origin_pos": 5, "tab": ["mxnet"]}, "outputs": [], "source": ["// bbox is the abbreviation for bounding box\n", "double[] dog_bbox = new double[]{60, 45, 378, 516};\n", "double[] cat_bbox = new double[]{400, 112, 655, 493};"]}, {"cell_type": "markdown", "metadata": {"origin_pos": 6}, "source": ["We can draw the bounding box in the image to check if it is accurate. Before drawing the box, we will define a helper function `bboxToRectangle`. In DJL, the rectangle we create are basically probabilities. Hence, we divide the coordinates by width and height respectively. It represents the bounding box in the bounding box format of DJL's `Image` API.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "3"}, "origin_pos": 7, "tab": ["mxnet"]}, "outputs": [], "source": ["public Rectangle bboxToRectangle(double[] bbox, int width, int height){\n", "    // Convert the coordinates into the \n", "    // bounding box coordinates format\n", "    return new Rectangle(bbox[0]/width, bbox[1]/height, (bbox[2]-bbox[0])/width, (bbox[3]-bbox[1])/height);\n", "}"]}, {"cell_type": "markdown", "metadata": {"origin_pos": 8}, "source": ["After loading the bounding box on the image, we can see that the main outline of the target is basically inside the box.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"origin_pos": 9, "tab": ["mxnet"]}, "outputs": [], "source": ["List<String> classNames = new ArrayList();\n", "        classNames.add(\"dog\");\n", "        classNames.add(\"cat\");\n", "\n", "List<Double> prob = new ArrayList<>();\n", "prob.add(1.0);\n", "prob.add(1.0);\n", "\n", "List<BoundingBox> boxes = new ArrayList<>();\n", "boxes.add(bboxToRectangle(dog_bbox, imgArr.getWidth(), imgArr.getHeight()));\n", "boxes.add(bboxToRectangle(cat_bbox, imgArr.getWidth(), imgArr.getHeight()));\n", "        \n", "DetectedObjects detectedObjects = new DetectedObjects(classNames, prob, boxes);\n", "\n", "// drawing the bounding boxes on the original image\n", "imgArr.drawBoundingBoxes(detectedObjects);\n", "imgArr.getWrappedImage();"]}, {"cell_type": "markdown", "metadata": {"origin_pos": 10}, "source": ["## Summary\n", "\n", "* In object detection, we not only need to identify all the objects of interest in the image, but also their positions. The positions are generally represented by a rectangular bounding box.\n", "\n", "## Exercises\n", "\n", "1. Find some images and try to label a bounding box that contains the target. Compare the difference between the time it takes to label the bounding box and label the category.\n"]}], "metadata": {"kernelspec": {"display_name": "Java", "language": "java", "name": "java"}, "language_info": {"codemirror_mode": "java", "file_extension": ".jshell", "mimetype": "text/x-java-source", "name": "Java", "pygments_lexer": "java", "version": "14.0.2+12"}}, "nbformat": 4, "nbformat_minor": 4}