{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°\n",
    ":label:`sec_attention-scoring-functions`\n",
    "\n",
    "åœ¨ :numref:`sec_nadaraya-waston` ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨é«˜æ–¯æ ¸æ¥å¯¹æŸ¥è¯¢å’Œé”®ä¹‹é—´çš„å…³ç³»å»ºæ¨¡ã€‚å¯ä»¥å°† :eqref:`eq_nadaraya-waston-gaussian` ä¸­çš„é«˜æ–¯æ ¸çš„æŒ‡æ•°éƒ¨åˆ†è§†ä¸º *æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ï¼ˆattention scoring functionï¼‰*ï¼Œç®€ç§° *è¯„åˆ†å‡½æ•°ï¼ˆscoring functionï¼‰*ï¼Œç„¶åæŠŠè¿™ä¸ªå‡½æ•°çš„è¾“å‡ºç»“æœè¾“å…¥åˆ° softmax å‡½æ•°ä¸­è¿›è¡Œè¿ç®—ã€‚é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œæˆ‘ä»¬å°†å¾—åˆ°ä¸é”®å¯¹åº”çš„å€¼çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆå³æ³¨æ„åŠ›æƒé‡ï¼‰ã€‚æœ€åï¼Œæ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºå°±æ˜¯åŸºäºè¿™äº›æ³¨æ„åŠ›æƒé‡çš„å€¼çš„åŠ æƒå’Œã€‚\n",
    "\n",
    "ä»å®è§‚æ¥çœ‹ï¼Œå¯ä»¥ä½¿ç”¨ä¸Šè¿°ç®—æ³•æ¥å®ç° :numref:`fig_qkv` ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶ã€‚:numref:`fig_attention_output` è¯´æ˜äº†å¦‚ä½•å°†æ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºè®¡ç®—æˆä¸ºå€¼çš„åŠ æƒå’Œï¼Œå…¶ä¸­  ğ‘  è¡¨ç¤ºæ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ã€‚ç”±äºæ³¨æ„åŠ›æƒé‡æ˜¯æ¦‚ç‡åˆ†å¸ƒï¼Œå› æ­¤åŠ æƒå’Œå…¶æœ¬è´¨ä¸Šæ˜¯åŠ æƒå¹³å‡å€¼ã€‚\n",
    "\n",
    "![è®¡ç®—æ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºä¸ºå€¼çš„åŠ æƒå’Œã€‚](https://zh-v2.d2l.ai/_images/attention-output.svg)\n",
    ":label:`fig_attention_output`\n",
    "\n",
    "\n",
    "\n",
    "Mathematically,\n",
    "suppose that we have\n",
    "a query $\\mathbf{q} \\in \\mathbb{R}^q$\n",
    "and $m$ key-value pairs $(\\mathbf{k}_1, \\mathbf{v}_1), \\ldots, (\\mathbf{k}_m, \\mathbf{v}_m)$, where any $\\mathbf{k}_i \\in \\mathbb{R}^k$ and any $\\mathbf{v}_i \\in \\mathbb{R}^v$.\n",
    "The attention pooling $f$\n",
    "is instantiated as a weighted sum of the values:\n",
    "\n",
    "$$f(\\mathbf{q}, (\\mathbf{k}_1, \\mathbf{v}_1), \\ldots, (\\mathbf{k}_m, \\mathbf{v}_m)) = \\sum_{i=1}^m \\alpha(\\mathbf{q}, \\mathbf{k}_i) \\mathbf{v}_i \\in \\mathbb{R}^v,$$\n",
    ":eqlabel:`eq_attn-pooling`\n",
    "\n",
    "\n",
    "ç”¨æ•°å­¦è¯­è¨€æè¿°ï¼Œå‡è®¾æœ‰ä¸€ä¸ªæŸ¥è¯¢ $\\mathbf{q} \\in \\mathbb{R}^q$ å’Œ $m$ ä¸ªé”®å€¼å¯¹ $(\\mathbf{k}_1, \\mathbf{v}_1), \\ldots, (\\mathbf{k}_m, \\mathbf{v}_m)$ï¼Œå…¶ä¸­ $\\mathbf{k}_i \\in \\mathbb{R}^k$ï¼Œ$\\mathbf{v}_i \\in \\mathbb{R}^v$ã€‚æ³¨æ„åŠ›æ±‡èšå‡½æ•°  ğ‘“  å°±è¢«è¡¨ç¤ºæˆå€¼çš„åŠ æƒå’Œï¼š\n",
    "\n",
    "$$f(\\mathbf{q}, (\\mathbf{k}_1, \\mathbf{v}_1), \\ldots, (\\mathbf{k}_m, \\mathbf{v}_m)) = \\sum_{i=1}^m \\alpha(\\mathbf{q}, \\mathbf{k}_i) \\mathbf{v}_i \\in \\mathbb{R}^v,$$\n",
    ":eqlabel:`eq_attn-pooling`\n",
    "\n",
    "å…¶ä¸­æŸ¥è¯¢ $\\mathbf{q}$ å’Œé”® $\\mathbf{k}_i$ çš„æ³¨æ„åŠ›æƒé‡ï¼ˆæ ‡é‡ï¼‰æ˜¯é€šè¿‡æ³¨æ„åŠ›è¯„åˆ†å‡½æ•° $a$ å°†ä¸¤ä¸ªå‘é‡æ˜ å°„æˆæ ‡é‡ï¼Œå†ç»è¿‡ softmax è¿ç®—å¾—åˆ°çš„ï¼š\n",
    "\n",
    "$$\\alpha(\\mathbf{q}, \\mathbf{k}_i) = \\mathrm{softmax}(a(\\mathbf{q}, \\mathbf{k}_i)) = \\frac{\\exp(a(\\mathbf{q}, \\mathbf{k}_i))}{\\sum_{j=1}^m \\exp(a(\\mathbf{q}, \\mathbf{k}_j))} \\in \\mathbb{R}.$$\n",
    ":eqlabel:`eq_attn-scoring-alpha`\n",
    "\n",
    "æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œé€‰æ‹©ä¸åŒçš„æ³¨æ„åŠ›è¯„åˆ†å‡½æ•° $a$ ä¼šå¯¼è‡´ä¸åŒçš„æ³¨æ„åŠ›æ±‡èšæ“ä½œã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸¤ä¸ªæµè¡Œçš„è¯„åˆ†å‡½æ•°ï¼Œç¨åå°†ç”¨ä»–ä»¬æ¥å®ç°æ›´å¤æ‚çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load ../utils/djl-imports\n",
    "%load ../utils/plot-utils\n",
    "%load ../utils/Functions.java\n",
    "%load ../utils/PlotUtils.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDManager manager = NDManager.newBaseManager(Functions.tryGpu(0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "## é®è”½softmaxæ“ä½œ\n",
    "\n",
    "æ­£å¦‚ä¸Šé¢æåˆ°çš„ï¼Œsoftmax è¿ç®—ç”¨äºè¾“å‡ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒä½œä¸ºæ³¨æ„åŠ›æƒé‡ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¹¶éæ‰€æœ‰çš„å€¼éƒ½åº”è¯¥è¢«çº³å…¥åˆ°æ³¨æ„åŠ›æ±‡èšä¸­ã€‚ä¾‹å¦‚ï¼Œä¸ºäº†åœ¨ :numref:`sec_machine_translation` ä¸­é«˜æ•ˆå¤„ç†å°æ‰¹é‡æ•°æ®é›†ï¼ŒæŸäº›æ–‡æœ¬åºåˆ—è¢«å¡«å……äº†æ²¡æœ‰æ„ä¹‰çš„ç‰¹æ®Šè¯å…ƒã€‚ä¸ºäº†ä»…å°†æœ‰æ„ä¹‰çš„è¯å…ƒä½œä¸ºå€¼å»è·å–æ³¨æ„åŠ›æ±‡èšï¼Œå¯ä»¥æŒ‡å®šä¸€ä¸ªæœ‰æ•ˆåºåˆ—é•¿åº¦ï¼ˆå³è¯å…ƒçš„ä¸ªæ•°ï¼‰ï¼Œä»¥ä¾¿åœ¨è®¡ç®— softmax æ—¶è¿‡æ»¤æ‰è¶…å‡ºæŒ‡å®šèŒƒå›´çš„ä½ç½®ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸‹é¢çš„ `maskedSoftmax` å‡½æ•°ä¸­å®ç°è¿™æ ·çš„ *é®è”½ softmax æ“ä½œï¼ˆmasked softmax operationï¼‰*ï¼Œå…¶ä¸­ä»»ä½•è¶…å‡ºæœ‰æ•ˆé•¿åº¦çš„ä½ç½®éƒ½è¢«é®è”½å¹¶ç½®ä¸º0ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public static NDArray maskedSoftmax(NDArray X, NDArray validLens) {\n",
    "    /* Perform softmax operation by masking elements on the last axis. */\n",
    "    // `X`: 3D NDArray, `validLens`: 1D or 2D NDArray\n",
    "    if (validLens == null) {\n",
    "        return X.softmax(-1);\n",
    "    } else {\n",
    "        Shape shape = X.getShape();\n",
    "        if (validLens.getShape().dimension() == 1) {\n",
    "            validLens = validLens.repeat(shape.get(1));\n",
    "        } else {\n",
    "            validLens = validLens.reshape(-1);\n",
    "        }\n",
    "        // On the last axis, replace masked elements with a very large negative\n",
    "        // value, whose exponentiation outputs 0\n",
    "        X =\n",
    "                X.reshape(new Shape(-1, shape.get(shape.dimension() - 1)))\n",
    "                        .sequenceMask(validLens, (float) -1E6);\n",
    "        return X.softmax(-1).reshape(shape);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "ä¸ºäº†æ¼”ç¤ºæ­¤å‡½æ•°æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œè€ƒè™‘ç”±ä¸¤ä¸ª $2 \\times 4$ çŸ©é˜µè¡¨ç¤ºçš„æ ·æœ¬ï¼Œè¿™ä¸¤ä¸ªæ ·æœ¬çš„æœ‰æ•ˆé•¿åº¦åˆ†åˆ«ä¸º2å’Œ3ã€‚ç»è¿‡é®è”½ softmax æ“ä½œï¼Œè¶…å‡ºæœ‰æ•ˆé•¿åº¦çš„å€¼éƒ½è¢«é®è”½ä¸º0ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedSoftmax(manager.randomUniform(0, 1, new Shape(2, 2, 4)),\n",
    "              manager.create(new float[] {2, 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "åŒæ ·ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨äºŒç»´å¼ é‡ä¸ºçŸ©é˜µæ ·æœ¬ä¸­çš„æ¯ä¸€è¡ŒæŒ‡å®šæœ‰æ•ˆé•¿åº¦ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedSoftmax(manager.randomUniform(0, 1, new Shape(2, 2, 4)),\n",
    "              manager.create(new float[][] {{1, 3}, {2, 4}}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## åŠ æ€§æ³¨æ„åŠ›\n",
    ":label:`subsec_additive-attention`\n",
    "\n",
    "\n",
    "ä¸€èˆ¬æ¥è¯´ï¼Œå½“æŸ¥è¯¢å’Œé”®æ˜¯ä¸åŒé•¿åº¦çš„çŸ¢é‡æ—¶ï¼Œå¯ä»¥ä½¿ç”¨åŠ æ€§æ³¨æ„åŠ›ä½œä¸ºè¯„åˆ†å‡½æ•°ã€‚ç»™å®šæŸ¥è¯¢ $\\mathbf{q} \\in \\mathbb{R}^q$\n",
    "å’Œé”® $\\mathbf{k} \\in \\mathbb{R}^k$ï¼Œ*åŠ æ€§æ³¨æ„åŠ›ï¼ˆadditive attentionï¼‰* çš„è¯„åˆ†å‡½æ•°ä¸º\n",
    "\n",
    "$$a(\\mathbf q, \\mathbf k) = \\mathbf w_v^\\top \\text{tanh}(\\mathbf W_q\\mathbf q + \\mathbf W_k \\mathbf k) \\in \\mathbb{R},$$\n",
    ":eqlabel:`eq_additive-attn`\n",
    "\n",
    "å…¶ä¸­å¯å­¦ä¹ çš„å‚æ•°æ˜¯ $\\mathbf W_q\\in\\mathbb R^{h\\times q}$, $\\mathbf W_k\\in\\mathbb R^{h\\times k}$, and $\\mathbf w_v\\in\\mathbb R^{h}$ ã€‚å¦‚ :eqref:`eq_additive-attn` æ‰€ç¤ºï¼Œå°†æŸ¥è¯¢å’Œé”®è¿æ¥èµ·æ¥åè¾“å…¥åˆ°ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ä¸­ï¼Œæ„ŸçŸ¥æœºåŒ…å«ä¸€ä¸ªéšè—å±‚ï¼Œå…¶éšè—å•å…ƒæ•°æ˜¯ä¸€ä¸ªè¶…å‚æ•° $h$ã€‚é€šè¿‡ä½¿ç”¨ $\\tanh$ ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå¹¶ä¸”ç¦ç”¨åç½®é¡¹ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹é¢å®ç°åŠ æ€§æ³¨æ„åŠ›ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Additive attention. */\n",
    "public class AdditiveAttention extends AbstractBlock {\n",
    "    private static final byte VERSION = 1;\n",
    "    private Linear W_k;\n",
    "    private Linear W_q;\n",
    "    private Linear W_v;\n",
    "    private Dropout dropout;\n",
    "    public NDArray attentionWeights;\n",
    "\n",
    "    public AdditiveAttention(int numHiddens, float dropout) {\n",
    "        super(VERSION);\n",
    "        this.W_k = Linear.builder().setUnits(numHiddens).optBias(false).build();\n",
    "        this.addChildBlock(\"W_k\", this.W_k);\n",
    "\n",
    "        this.W_q = Linear.builder().setUnits(numHiddens).optBias(false).build();\n",
    "        this.addChildBlock(\"W_q\", this.W_q);\n",
    "\n",
    "        this.W_v = Linear.builder().setUnits(1).optBias(false).build();\n",
    "        this.addChildBlock(\"W_v\", this.W_v);\n",
    "\n",
    "        this.dropout = Dropout.builder().optRate(dropout).build();\n",
    "        this.addChildBlock(\"dropout\", this.dropout);\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    protected NDList forwardInternal(\n",
    "            ParameterStore parameterStore,\n",
    "            NDList inputs,\n",
    "            boolean training,\n",
    "            PairList<String, Object> params) {\n",
    "        // Shape of the output `queries` and `attentionWeights`:\n",
    "        // (no. of queries, no. of key-value pairs)\n",
    "        NDArray queries = inputs.get(0);\n",
    "        NDArray keys = inputs.get(1);\n",
    "        NDArray values = inputs.get(2);\n",
    "        NDArray validLens = inputs.get(3);\n",
    "\n",
    "        queries = this.W_q.forward(parameterStore, new NDList(queries), training, params).head();\n",
    "        keys = this.W_k.forward(parameterStore, new NDList(keys), training, params).head();\n",
    "        // After dimension expansion, shape of `queries`: (`batchSize`, no. of\n",
    "        // queries, 1, `numHiddens`) and shape of `keys`: (`batchSize`, 1,\n",
    "        // no. of key-value pairs, `numHiddens`). Sum them up with\n",
    "        // broadcasting\n",
    "        NDArray features = queries.expandDims(2).add(keys.expandDims(1));\n",
    "        features = features.tanh();\n",
    "        // There is only one output of `this.W_v`, so we remove the last\n",
    "        // one-dimensional entry from the shape. Shape of `scores`:\n",
    "        // (`batchSize`, no. of queries, no. of key-value pairs)\n",
    "        NDArray result =\n",
    "                this.W_v.forward(parameterStore, new NDList(features), training, params).head();\n",
    "        NDArray scores = result.squeeze(-1);\n",
    "        this.attentionWeights = maskedSoftmax(scores, validLens);\n",
    "        // Shape of `values`: (`batchSize`, no. of key-value pairs, value\n",
    "        // dimension)\n",
    "        return new NDList(\n",
    "                this.dropout\n",
    "                        .forward(\n",
    "                                parameterStore, new NDList(this.attentionWeights), training, params)\n",
    "                        .head()\n",
    "                        .batchDot(values));\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public Shape[] getOutputShapes(Shape[] inputShapes) {\n",
    "        throw new UnsupportedOperationException(\"Not implemented\");\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public void initializeChildBlocks(NDManager manager, DataType dataType, Shape... inputShapes) {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªå°ä¾‹å­æ¥æ¼”ç¤ºä¸Šé¢çš„ `AdditiveAttention` ç±»ï¼Œå…¶ä¸­æŸ¥è¯¢ã€é”®å’Œå€¼çš„å½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ã€æ­¥æ•°æˆ–è¯å…ƒåºåˆ—é•¿åº¦ã€ç‰¹å¾å¤§å°ï¼‰ï¼Œå®é™…è¾“å‡ºä¸º  ($2$, $1$, $20$), ($2$, $10$, $2$) å’Œ ($2$, $10$, $4$)ã€‚æ³¨æ„åŠ›æ±‡èšè¾“å‡ºçš„å½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ã€æŸ¥è¯¢çš„æ­¥æ•°ã€å€¼çš„ç»´åº¦ï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDArray queries = manager.randomNormal(0, 1, new Shape(2, 1, 20), DataType.FLOAT32);\n",
    "NDArray keys = manager.ones(new Shape(2, 10, 2));\n",
    "// The two value matrices in the `values` minibatch are identical\n",
    "NDArray values = manager.arange(40f).reshape(1, 10, 4).repeat(0, 2);\n",
    "NDArray validLens = manager.create(new float[] {2, 6});\n",
    "\n",
    "AdditiveAttention attention = new AdditiveAttention(8, 0.1f);\n",
    "attention\n",
    "        .forward(\n",
    "                new ParameterStore(manager, false),\n",
    "                new NDList(queries, keys, values, validLens),\n",
    "                false)\n",
    "        .head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "å°½ç®¡åŠ æ€§æ³¨æ„åŠ›åŒ…å«äº†å¯å­¦ä¹ çš„å‚æ•°ï¼Œä½†ç”±äºæœ¬ä¾‹å­ä¸­æ¯ä¸ªé”®éƒ½æ˜¯ç›¸åŒçš„ï¼Œæ‰€ä»¥æ³¨æ„åŠ›æƒé‡æ˜¯å‡åŒ€çš„ï¼Œç”±æŒ‡å®šçš„æœ‰æ•ˆé•¿åº¦å†³å®šã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotUtils.showHeatmaps(\n",
    "            attention.attentionWeights.reshape(1, 1, 2, 10),\n",
    "            \"Keys\",\n",
    "            \"Queries\",\n",
    "            new String[] {\"\"},\n",
    "            500,\n",
    "            700);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›\n",
    "\n",
    "ä½¿ç”¨ç‚¹ç§¯å¯ä»¥å¾—åˆ°è®¡ç®—æ•ˆç‡æ›´é«˜çš„è¯„åˆ†å‡½æ•°ã€‚ä½†æ˜¯ç‚¹ç§¯æ“ä½œè¦æ±‚æŸ¥è¯¢å’Œé”®å…·æœ‰ç›¸åŒçš„é•¿åº¦ $d$ã€‚å‡è®¾æŸ¥è¯¢å’Œé”®çš„æ‰€æœ‰å…ƒç´ éƒ½æ˜¯ç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œå¹¶ä¸”éƒ½æ»¡è¶³å‡å€¼ä¸º0å’Œæ–¹å·®ä¸ºã€‚é‚£ä¹ˆä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯çš„å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º $d$ã€‚ä¸ºç¡®ä¿æ— è®ºå‘é‡é•¿åº¦å¦‚ä½•ï¼Œç‚¹ç§¯çš„æ–¹å·®åœ¨ä¸è€ƒè™‘å‘é‡é•¿åº¦çš„æƒ…å†µä¸‹ä»ç„¶æ˜¯1ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ *ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ï¼ˆscaled dot-product attentionï¼‰* è¯„åˆ†å‡½æ•°ï¼š\n",
    "\n",
    "$$a(\\mathbf q, \\mathbf k) = \\mathbf{q}^\\top \\mathbf{k}  /\\sqrt{d}$$\n",
    "\n",
    "å°†ç‚¹ç§¯é™¤ä»¥ $\\sqrt{d}$ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä»å°æ‰¹é‡çš„è§’åº¦æ¥è€ƒè™‘æé«˜æ•ˆç‡ï¼Œä¾‹å¦‚åŸºäº $n$ ä¸ªæŸ¥è¯¢å’Œ $m$ ä¸ªé”®ï¼å€¼å¯¹è®¡ç®—æ³¨æ„åŠ›ï¼Œå…¶ä¸­æŸ¥è¯¢å’Œé”®çš„é•¿åº¦ä¸º $d$ï¼Œå€¼çš„é•¿åº¦ä¸º $v$ã€‚æŸ¥è¯¢ $\\mathbf Q\\in\\mathbb R^{n\\times d}$ï¼Œé”® $\\mathbf K\\in\\mathbb R^{m\\times d}$ å’Œå€¼ $\\mathbf V\\in\\mathbb R^{m\\times v}$ çš„ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›æ˜¯\n",
    "\n",
    "$$ \\mathrm{softmax}\\left(\\frac{\\mathbf Q \\mathbf K^\\top }{\\sqrt{d}}\\right) \\mathbf V \\in \\mathbb{R}^{n\\times v}.$$\n",
    ":eqlabel:`eq_softmax_QK_V`\n",
    "\n",
    "åœ¨ä¸‹é¢çš„ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† dropout è¿›è¡Œæ¨¡å‹æ­£åˆ™åŒ–ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Scaled dot product attention. */\n",
    "public class DotProductAttention extends AbstractBlock {\n",
    "    private static final byte VERSION = 1;\n",
    "    private Dropout dropout;\n",
    "    public NDArray attentionWeights;\n",
    "\n",
    "    public DotProductAttention(float dropout) {\n",
    "        super(VERSION);\n",
    "\n",
    "        this.dropout = Dropout.builder().optRate(dropout).build();\n",
    "        this.addChildBlock(\"dropout\", this.dropout);\n",
    "        this.dropout.setInitializer(new UniformInitializer(0.07f), Parameter.Type.WEIGHT);\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    protected NDList forwardInternal(\n",
    "            ParameterStore parameterStore,\n",
    "            NDList inputs,\n",
    "            boolean training,\n",
    "            PairList<String, Object> params) {\n",
    "        // Shape of `queries`: (`batchSize`, no. of queries, `d`)\n",
    "        // Shape of `keys`: (`batchSize`, no. of key-value pairs, `d`)\n",
    "        // Shape of `values`: (`batchSize`, no. of key-value pairs, value\n",
    "        // dimension)\n",
    "        // Shape of `valid_lens`: (`batchSize`,) or (`batchSize`, no. of queries)\n",
    "        NDArray queries = inputs.head();\n",
    "        NDArray keys = inputs.get(1);\n",
    "        NDArray values = inputs.get(2);\n",
    "        NDArray validLens = inputs.get(3);\n",
    "\n",
    "        Long d = queries.getShape().get(queries.getShape().dimension() - 1);\n",
    "        // Swap the last two dimensions of `keys` and perform batchDot\n",
    "        NDArray scores = queries.batchDot(keys.swapAxes(1, 2)).div(Math.sqrt(2));\n",
    "        attentionWeights = maskedSoftmax(scores, validLens);\n",
    "        return new NDList(\n",
    "                this.dropout\n",
    "                        .forward(\n",
    "                                parameterStore, new NDList(this.attentionWeights), training, params)\n",
    "                        .head()\n",
    "                        .batchDot(values));\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public Shape[] getOutputShapes(Shape[] inputShapes) {\n",
    "        throw new UnsupportedOperationException(\"Not implemented\");\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public void initializeChildBlocks(NDManager manager, DataType dataType, Shape... inputShapes) {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "ä¸ºäº†æ¼”ç¤ºä¸Šè¿°çš„ `DotProductAttention` ç±»ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸å…ˆå‰åŠ æ€§æ³¨æ„åŠ›ä¾‹å­ä¸­ç›¸åŒçš„é”®ã€å€¼å’Œæœ‰æ•ˆé•¿åº¦ã€‚å¯¹äºç‚¹ç§¯æ“ä½œï¼Œä»¤æŸ¥è¯¢çš„ç‰¹å¾ç»´åº¦ä¸é”®çš„ç‰¹å¾ç»´åº¦å¤§å°ç›¸åŒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = manager.randomNormal(0, 1, new Shape(2, 1, 2), DataType.FLOAT32);\n",
    "DotProductAttention productAttention = new DotProductAttention(0.5f);\n",
    "productAttention\n",
    "        .forward(\n",
    "                new ParameterStore(manager, false),\n",
    "                new NDList(queries, keys, values, validLens),\n",
    "                false)\n",
    "        .head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "ä¸åŠ æ€§æ³¨æ„åŠ›æ¼”ç¤ºç›¸åŒï¼Œç”±äº`é”®` åŒ…å«çš„æ˜¯ç›¸åŒçš„å…ƒç´ ï¼Œè€Œè¿™äº›å…ƒç´ æ— æ³•é€šè¿‡ä»»ä½•æŸ¥è¯¢è¿›è¡ŒåŒºåˆ†ï¼Œå› æ­¤è·å¾—äº†å‡åŒ€çš„æ³¨æ„åŠ›æƒé‡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotUtils.showHeatmaps(\n",
    "        productAttention.attentionWeights.reshape(1, 1, 2, 10),\n",
    "        \"Keys\",\n",
    "        \"Queries\",\n",
    "        new String[] {\"\"},\n",
    "        500,\n",
    "        700);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "## å°ç»“\n",
    "\n",
    "* å¯ä»¥å°†æ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºè®¡ç®—ä½œä¸ºå€¼çš„åŠ æƒå¹³å‡ï¼Œé€‰æ‹©ä¸åŒçš„æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ä¼šå¸¦æ¥ä¸åŒçš„æ³¨æ„åŠ›æ±‡èšæ“ä½œã€‚\n",
    "* å½“æŸ¥è¯¢å’Œé”®æ˜¯ä¸åŒé•¿åº¦çš„çŸ¢é‡æ—¶ï¼Œå¯ä»¥ä½¿ç”¨å¯åŠ æ€§æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ã€‚å½“å®ƒä»¬çš„é•¿åº¦ç›¸åŒæ—¶ï¼Œä½¿ç”¨ç¼©æ”¾çš„â€œç‚¹ï¼ç§¯â€æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°çš„è®¡ç®—æ•ˆç‡æ›´é«˜ã€‚\n",
    "\n",
    "\n",
    "## ç»ƒä¹ \n",
    "\n",
    "1. ä¿®æ”¹å°ä¾‹å­ä¸­çš„é”®ï¼Œå¹¶ä¸”å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡ã€‚å¯åŠ æ€§æ³¨æ„åŠ›å’Œç¼©æ”¾çš„â€œç‚¹ï¼ç§¯â€æ³¨æ„åŠ›æ˜¯å¦ä»ç„¶äº§ç”Ÿç›¸åŒçš„ç»“æœï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
    "1. åªä½¿ç”¨çŸ©é˜µä¹˜æ³•ï¼Œæ‚¨èƒ½å¦ä¸ºå…·æœ‰ä¸åŒçŸ¢é‡é•¿åº¦çš„æŸ¥è¯¢å’Œé”®è®¾è®¡æ–°çš„è¯„åˆ†å‡½æ•°ï¼Ÿ\n",
    "1. å½“æŸ¥è¯¢å’Œé”®å…·æœ‰ç›¸åŒçš„çŸ¢é‡é•¿åº¦æ—¶ï¼ŒçŸ¢é‡æ±‚å’Œä½œä¸ºè¯„åˆ†å‡½æ•°æ˜¯å¦æ¯”â€œç‚¹ï¼ç§¯â€æ›´å¥½ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "14.0.2+12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
